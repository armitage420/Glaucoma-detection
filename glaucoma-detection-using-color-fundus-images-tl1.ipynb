{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Version 2\n# Preprocessing: Optical Disk localised manually\n# --Very few data to create an automated optical disk optimisation","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Transfer learning on already trained ResNet50. Compile process.\n\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\ncategories = 2\n\nmodel = Sequential()\n\n# The fully connected top layer of ResNet50 is not to added in this model\nmodel.add(ResNet50(include_top = False, pooling = 'avg', weights = 'imagenet'))\n\n# All inputs and outputs are connected to neurons (Dense Layers)\n# ReLu activation can be used here. Difference --?\nmodel.add(Dense(categories, activation='softmax'))\nmodel.layers[0].trainable = False\n\nmodel.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])","execution_count":1,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94773248/94765736 [==============================] - 1s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input/drishtiiiitlocalisedfundus/Test/Test\"))","execution_count":2,"outputs":[{"output_type":"stream","text":"['Glaucomatous', 'Normal']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\npngCounter = len(glob.glob1('../input/drishtiiiitlocalisedfundus/Test/Test/Glaucomatous',\"*.png\")) + len(glob.glob1('../input/drishtiiiitlocalisedfundus/Test/Test/Normal',\"*.png\"))\nprint(pngCounter)","execution_count":3,"outputs":[{"output_type":"stream","text":"51\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\npngCounter = len(glob.glob1('../input/drishtiiiitlocalisedfundus/Training/Training/Glaucomatous',\"*.png\")) + len(glob.glob1('../input/drishtiiiitlocalisedfundus/Training/Training/Normal',\"*.png\"))\nprint(pngCounter)","execution_count":4,"outputs":[{"output_type":"stream","text":"50\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":5,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet50 (Model)             (None, 2048)              23587712  \n_________________________________________________________________\ndense (Dense)                (None, 2)                 4098      \n=================================================================\nTotal params: 23,591,810\nTrainable params: 4,098\nNon-trainable params: 23,587,712\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Fitting\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\n\ndata_generator = ImageDataGenerator(preprocess_input)\n\nimage_size = 224\n\ntrain_generator = data_generator.flow_from_directory(directory = '../input/drishtiiiitlocalisedfundus/Training/Training',\n                                                     target_size = (image_size, image_size),\n                                                     batch_size = 5,\n                                                     class_mode = 'categorical')\n\nvalidation_generator = data_generator.flow_from_directory(directory = '../input/drishtiiiitlocalisedfundus/Test/Test',\n                                                          target_size = (image_size, image_size),\n                                                         batch_size = 51,\n                                                         class_mode = 'categorical')\n","execution_count":6,"outputs":[{"output_type":"stream","text":"Found 50 images belonging to 2 classes.\nFound 51 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fitting = model.fit_generator(\n        train_generator,\n        steps_per_epoch=3,\n        epochs = 3,\n        validation_data=validation_generator,\n        validation_steps=1\n)","execution_count":21,"outputs":[{"output_type":"stream","text":"Epoch 1/3\n3/3 [==============================] - 5s 2s/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 1.4770 - val_accuracy: 0.4000\nEpoch 2/3\n3/3 [==============================] - 5s 2s/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 1.2561 - val_accuracy: 0.5000\nEpoch 3/3\n3/3 [==============================] - 5s 2s/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.9850 - val_accuracy: 0.7000\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}